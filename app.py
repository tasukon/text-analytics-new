import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import japanize_matplotlib
from janome.tokenizer import Tokenizer
from collections import Counter
from wordcloud import WordCloud
import networkx as nx
import itertools
import time

# --- 1. „Ç¢„Éó„É™„ÅÆÂü∫Êú¨Ë®≠ÂÆö ---
st.set_page_config(
    page_title="Text Analytics App",
    page_icon="üìä",
    layout="wide"
)

# „Çª„ÉÉ„Ç∑„Éß„É≥„Çπ„ÉÜ„Éº„ÉàÔºà„Éá„Éº„Çø„ÅÆË®òÊÜ∂Â†¥ÊâÄÔºâ„ÅÆÂàùÊúüÂåñ
if 'df' not in st.session_state:
    st.session_state.df = None

# „Çπ„Éà„ÉÉ„Éó„ÉØ„Éº„Éâ„ÅÆÂÆöÁæ©ÔºàÂæå„ÅßËá™ÂãïÂåñÊ©üËÉΩ„ÇíÂº∑Âåñ„Åó„Åæ„Åô„Åå„ÄÅ‰∏ÄÊó¶„Åì„ÅÆ„Åæ„ÅæÔºâ
DEFAULT_STOPWORDS = [
    "„ÅÆ", "„Å´", "„ÅØ", "„Çí", "„Åü", "„Åå", "„Åß", "„Å¶", "„Å®", "„Åó", "„Çå", "„Åï",
    "„ÅÇ„Çã", "„ÅÑ„Çã", "„ÇÇ", "„Åô„Çã", "„Åã„Çâ", "„Å™", "„Åì„Å®", "„Å®„Åó„Å¶", "„ÅÑ", "„ÇÑ",
    "„Çå„Çã", "„Å™„Å©", "„Å™„ÅÑ", "„Åì„ÅÆ", "„Åü„ÇÅ", "„Åù„ÅÆ", "„Çà„ÅÜ", "„Åæ„Åü", "„ÇÇ„ÅÆ",
    "„Åæ„Åô", "„Åß„Åô", "„Åï„Çì", "„Å°„ÇÉ„Çì", "„Åè„Çì", "„ÅÇ„Å£", "„ÅÇ„Çä", "„ÅÑ„Å£", "„ÅÜ",
    "„Åã", "„Åõ„Çã", "„Åü„ÅÑ", "„Å†„Åë", "„Åü„Å°", "„Å§„ÅÑ„Å¶", "„Åß„Åç", "„Å™„Çä", "„ÅÆ",
    "„Å∞„Åã„Çä", "„Åª„Å©", "„Åæ„Åß", "„Åæ„Åæ", "„Çà„ÅÜ", "„Çà„Çä", "„Çè„Åü„Åó"
]

# --- 2. Èñ¢Êï∞ÂÆöÁæ© ---

@st.cache_data
def get_tokens(text, stop_words):
    """„ÉÜ„Ç≠„Çπ„Éà„Åã„ÇâÂêçË©û„ÉªÂãïË©û„ÉªÂΩ¢ÂÆπË©û„ÇíÊäΩÂá∫"""
    t = Tokenizer()
    tokens = []
    if not isinstance(text, str):
        return []
    
    for token in t.tokenize(text):
        base = token.base_form
        pos = token.part_of_speech.split(',')[0]
        if pos in ['ÂêçË©û', 'ÂãïË©û', 'ÂΩ¢ÂÆπË©û'] and len(base) > 1 and base not in stop_words:
            tokens.append(base)
    return tokens

@st.cache_data
def create_cooccurrence_network(tokens_list, top_n=50, min_edge_weight=1):
    """ÂÖ±Ëµ∑„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Çí‰ΩúÊàê"""
    pair_list = []
    for tokens in tokens_list:
        if len(tokens) >= 2:
            pair_list.extend(itertools.combinations(tokens, 2))
    
    c = Counter(pair_list)
    top_pairs = c.most_common(top_n)
    
    G = nx.Graph()
    for (u, v), weight in top_pairs:
        if weight >= min_edge_weight:
            G.add_edge(u, v, weight=weight)
    return G

@st.cache_data
def create_demo_data():
    """„Éá„É¢„Éá„Éº„ÇøÁîüÊàê"""
    data = {
        'Â≠¶Âπ¥': ['1Âπ¥', '1Âπ¥', '2Âπ¥', '2Âπ¥', '3Âπ¥', '3Âπ¥', '1Âπ¥', '2Âπ¥', '3Âπ¥', '1Âπ¥'],
        'ÊÄßÂà•': ['Áî∑ÊÄß', 'Â•≥ÊÄß', 'Áî∑ÊÄß', 'Â•≥ÊÄß', 'Áî∑ÊÄß', 'Â•≥ÊÄß', 'Â•≥ÊÄß', 'Áî∑ÊÄß', 'Â•≥ÊÄß', 'Áî∑ÊÄß'],
        'Ëá™Áî±Ë®òËø∞': [
            'ÈáéÊÄßÂë≥„ÅÇ„Åµ„Çå„Çã‰∫∫Êùê„Å´„Å™„Çä„Åü„ÅÑ„Åó„ÄÅ‰æ°ÂÄ§ÂâµÈÄ†„ÇÇÈáçË¶Å„Å†„Å®ÊÄù„ÅÜ„ÄÇ',
            'Êñ∞„Åó„ÅÑ‰æ°ÂÄ§„Çí‰Ωú„Çã„Åü„ÇÅ„Å´„ÅØ„ÄÅÈáéÊÄßÁöÑ„Å™Âãò„ÅåÂøÖË¶Å„Å†„Å®ÊÑü„Åò„Çã„ÄÇ',
            'Â≠¶Ê†°ÁîüÊ¥ª„ÅßÈáéÊÄßÂë≥„ÇíÁ£®„Åç„ÄÅÁ§æ‰ºö„ÅßÊ¥ªË∫ç„Åó„Åü„ÅÑ„ÄÇ',
            '‰æ°ÂÄ§ÂâµÈÄ†‰∫∫Êùê„Å®„ÅØ„ÄÅÂ§±Êïó„ÇíÊÅê„Çå„Åö„Å´ÊåëÊà¶„Åô„Çã‰∫∫„ÅÆ„Åì„Å®„Å†„ÄÇ',
            '‰æ°ÂÄ§ÂâµÈÄ†‰∫∫Êùê„Å®„ÅØ„ÄÅÂ§±Êïó„ÇíÊÅê„Çå„Åö„Å´ÊåëÊà¶„Åô„Çã‰∫∫„ÅÆ„Åì„Å®„Å†„ÄÇ',
            'Â∞ÜÊù•„ÅØ„ÇØ„É™„Ç®„Ç§„ÉÜ„Ç£„Éñ„Å™‰ªï‰∫ã„Åß‰æ°ÂÄ§„ÇíÁîü„ÅøÂá∫„Åó„Åü„ÅÑ„ÄÇ',
            'ÈáéÊÄßÂë≥„Å®„ÅØ„ÄÅÂõ∞Èõ£„Å´Á´ã„Å°Âêë„Åã„ÅÜÂº∑„Åï„ÅÆ„Åì„Å®„Å†„Å®ÊÄù„ÅÜ„ÄÇ',
            '‰ª≤Èñì„Å®ÂçîÂäõ„Åó„Å¶Êñ∞„Åó„ÅÑ‰æ°ÂÄ§„ÇíÂâµÈÄ†„Åô„Çã„Åì„Å®„ÅåÁõÆÊ®ô„Åß„Åô„ÄÇ',
            '„ÇÇ„Å£„Å®Ëá™Áî±„Å´„ÄÅÈáéÊÄßÁöÑ„Å´Áîü„Åç„Å¶„ÅÑ„Åç„Åü„ÅÑ„ÄÇ',
            '‰æ°ÂÄ§ÂâµÈÄ†„ÅÆ„Åü„ÇÅ„Å´„ÅØ„ÄÅÂü∫Á§éÁöÑ„Å™Áü•Ë≠ò„ÇÇÂ§ßÂàá„Å†„ÄÇ'
        ]
    }
    return pd.DataFrame(data)

# --- 3. „É°„Ç§„É≥ÁîªÈù¢Âà∂Âæ° ---

# „Éá„Éº„Çø„Åå„Å™„ÅÑÊôÇÔºàStep 1Ôºâ„Å® „ÅÇ„ÇãÊôÇÔºàStep 2Ôºâ„ÅßË°®Á§∫„ÇíÂàÜ„Åë„Çã

if st.session_state.df is None:
    # === Step 1: „Éá„Éº„ÇøË™≠„ÅøËæº„ÅøÁîªÈù¢ ===
    st.title("üìÇ „Éá„Éº„Çø„ÅÆË™≠„ÅøËæº„Åø")
    st.markdown("##### ÂàÜÊûê„Åó„Åü„ÅÑ„Éï„Ç°„Ç§„É´ÔºàCSV „Åæ„Åü„ÅØ ExcelÔºâ„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
    
    # „Éï„Ç°„Ç§„É´„Ç¢„ÉÉ„Éó„É≠„Éº„ÉÄ„ÉºÔºàCSV„Å®Excel„ÅÆ‰∏°Êñπ„Å´ÂØæÂøúÔºâ
    uploaded_file = st.file_uploader("„Åì„Åì„Å´„Éï„Ç°„Ç§„É´„Çí„Éâ„É©„ÉÉ„Ç∞ÔºÜ„Éâ„É≠„ÉÉ„Éó", type=['csv', 'xlsx'])

    if uploaded_file is not None:
        try:
            with st.spinner("„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„Çì„Åß„ÅÑ„Åæ„Åô..."):
                # Êã°ÂºµÂ≠ê„ÇíË¶ã„Å¶Ë™≠„ÅøËæº„ÅøÊñπ„ÇíÂ§â„Åà„Çã
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                
                # „Éá„Éº„Çø„Çí‰øùÂ≠ò„Åó„Å¶ÂÜçË™≠„ÅøËæº„ÅøÔºàÊ¨°„ÅÆÁîªÈù¢„Å∏Ôºâ
                st.session_state.df = df
                st.rerun()
        except Exception as e:
            st.error(f"Ë™≠„ÅøËæº„Åø„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {e}")

    # „Éá„É¢„Éá„Éº„Çø„ÅßË©¶„Åô„Éú„Çø„É≥ÔºàÊéß„Åà„ÇÅ„Å´ÈÖçÁΩÆÔºâ
    st.markdown("---")
    if st.button("„Åæ„Åö„ÅØ„Éá„É¢„Éá„Éº„Çø„ÅßË©¶„Åô"):
        st.session_state.df = create_demo_data()
        st.rerun()

else:
    # === Step 2: ÂàÜÊûêÁîªÈù¢ ===
    df = st.session_state.df
    
    # „Çµ„Ç§„Éâ„Éê„ÉºÔºö„É™„Çª„ÉÉ„Éà„Éú„Çø„É≥
    with st.sidebar:
        st.title("„É°„Éã„É•„Éº")
        if st.button("üîÑ Âà•„ÅÆ„Éá„Éº„Çø„ÇíË™≠„ÅøËæº„ÇÄ"):
            st.session_state.df = None
            st.rerun()
        st.markdown("---")
        st.markdown("### ÂàÜÊûêË®≠ÂÆö")

    st.title("üìä ÂàÜÊûê„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ")

    # ÂàÜÊûê„Åô„ÇãÂàó„ÅÆÈÅ∏ÊäûÔºà„Çµ„Ç§„Éâ„Éê„Éº„Å´ÈÖçÁΩÆÔºâ
    all_cols = df.columns
    target_col = st.sidebar.selectbox("ÂàÜÊûê„Åô„Çã„ÉÜ„Ç≠„Çπ„Éà„ÅÆÂàó", all_cols, index=len(all_cols)-1)

    # „Çø„Éñ„ÅßÊ©üËÉΩ„ÇíÂàá„ÇäÊõø„Åà
    tab1, tab2, tab3, tab4 = st.tabs(["üìÇ „Éá„Éº„ÇøÁ¢∫Ë™ç", "üìà È†ªÂá∫ÂçòË™û", "‚òÅÔ∏è „ÉØ„Éº„Éâ„ÇØ„É©„Ç¶„Éâ", "üï∏Ô∏è ÂÖ±Ëµ∑„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ"])

    with tab1:
        st.markdown(f"**„Éá„Éº„Çø‰ª∂Êï∞:** {len(df)} Ë°å")
        st.dataframe(df)

    with tab2:
        st.subheader("È†ªÂá∫ÂçòË™û„É©„É≥„Ç≠„É≥„Ç∞")
        top_n = st.slider("Ë°®Á§∫‰ª∂Êï∞", 5, 50, 10, key='bar_slider')
        
        if st.button("„Ç∞„É©„Éï„ÇíË°®Á§∫", key='btn_bar'):
            with st.spinner("ÈõÜË®à‰∏≠..."):
                text_data = " ".join(df[target_col].dropna().astype(str).tolist())
                tokens = get_tokens(text_data, DEFAULT_STOPWORDS)
                if tokens:
                    counter = Counter(tokens)
                    words, counts = zip(*counter.most_common(top_n))
                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.barh(words, counts, color='skyblue')
                    ax.invert_yaxis()
                    st.pyplot(fig)
                else:
                    st.warning("ÂçòË™û„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü")

    with tab3:
        st.subheader("„ÉØ„Éº„Éâ„ÇØ„É©„Ç¶„Éâ")
        if st.button("‰ΩúÊàê„Åô„Çã", key='btn_wc'):
            with st.spinner("ÊèèÁîª‰∏≠..."):
                text_data = " ".join(df[target_col].dropna().astype(str).tolist())
                tokens = get_tokens(text_data, DEFAULT_STOPWORDS)
                text_space_sep = " ".join(tokens)
                try:
                    wc = WordCloud(
                        background_color="white", width=800, height=500,
                        regexp=r"[\w']+", font_path="IPAexGothic.ttf"
                    ).generate(text_space_sep)
                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.imshow(wc, interpolation='bilinear')
                    ax.axis("off")
                    st.pyplot(fig)
                except Exception as e:
                    st.error("„Ç®„É©„Éº: „Éï„Ç©„É≥„ÉàË®≠ÂÆö„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ")

    with tab4:
        st.subheader("ÂÖ±Ëµ∑„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ")
        col1, col2 = st.columns(2)
        with col1:
            net_top_n = st.slider("„Ç®„ÉÉ„Ç∏Êï∞", 10, 100, 50, key='net_slider')
        with col2:
            min_edge = st.slider("ÊúÄÂ∞èÂÖ±Ëµ∑ÂõûÊï∞", 1, 5, 1, key='net_edge')

        if st.button("„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÇíË°®Á§∫", key='btn_net'):
            with st.spinner("ÊßãÁØâ‰∏≠..."):
                sentences = df[target_col].dropna().astype(str).tolist()
                tokens_list = [get_tokens(s, DEFAULT_STOPWORDS) for s in sentences]
                G = create_cooccurrence_network(tokens_list, top_n=net_top_n, min_edge_weight=min_edge)
                
                if G.number_of_nodes() > 0:
                    fig, ax = plt.subplots(figsize=(10, 10))
                    pos = nx.spring_layout(G, k=0.6, seed=42)
                    nx.draw_networkx_nodes(G, pos, node_size=300, node_color='lightblue', alpha=0.9, ax=ax)
                    nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5, edge_color='gray', ax=ax)
                    nx.draw_networkx_labels(G, pos, font_family='IPAexGothic', font_size=11, ax=ax)
                    ax.axis('off')
                    st.pyplot(fig)
                else:
                    st.warning("„Å§„Å™„Åå„Çä„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
